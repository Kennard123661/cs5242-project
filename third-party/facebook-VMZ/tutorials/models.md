# Download and evaluate pre-trained models

We release various pre-trained models with the hope that they will help to reproduce results and facilitate research experiments in video modeling. * Pre-trained models can be downloaded [here](https://www.dropbox.com/sh/ofdd6ia32eo4wk5/AAA8553of0M2tQVlfR0S2GTFa). More details about these models are below:

| Model | Input size | Pre-trained | Clip@1 | Video@1 | Video@5 | GLOPs | Params (M)|Download |
| ----- | ---------- | ----------- | ------ | ------- | ------- | ----- | --------- |---------|
| **R2.5D-18** | 8x112x112  | Kinetics | 53.2   | 65.3    | 85.2    | 20.7  | 33.3      | [link](https://www.dropbox.com/s/wzgx4d80mrh7pnf/r2.5d_d18_l8.pkl?dl=0) |
| R3D-18   | 8x112x112  | Kinetics | 49.8   |	62.3  |	83.4	| 20.3  |	33.4    | [link](https://www.dropbox.com/s/n3ax2591imcy9ly/r3d_d18_l8.pkl?dl=0) |
| R2D-18   | 8x112x112  | Kinetics | 47     |	60      |	81.2    |	1.9   |	11.4      | [link](https://www.dropbox.com/s/ju4fah9dksn08s1/r2d_d18_l8.pkl?dl=0)|
| fR2D-18  | 8x112x112  | Kinetics | 48.5   |	60      |	81.8    | 13.8  |	11.4      | [link](https://www.dropbox.com/s/4jexszps3564za3/r2df_d18_l8.pkl?dl=0)|
| MC2-18   | 8x112x112  | Kinetics | 50.6   |	63      |	83.8    |	14.3  |	11.4      |[link](https://www.dropbox.com/s/lkmhyjok8odtv8e/mc2_d18_l8.pkl?dl=0)|
| MC3-18   | 8x112x112  | Kinetics | 51.1   |	63.3    | 84.2    |	21.7  |	11.7      |[link](https://www.dropbox.com/s/3jxzhc3kduyrpik/mc3_d18_l8.pkl?dl=0)|
| MC4-18   | 8x112x112  | Kinetics | 50.9   |	63      | 84.2    |	20	  | 12.7      |[link](https://www.dropbox.com/s/vx2xee36et823gs/mc4_d18_l8.pkl?dl=0)|
| MC5-18   | 8x112x112  | Kinetics | 50.7   |	62.9    | 84.2    |	20    | 16.8      |[link](https://www.dropbox.com/s/z6fxv6jr30i2lwz/mc5_d18_l8.pkl?dl=0)|
| rMC2-18  | 8x112x112  | Kinetics | 50.2   |	62.7    | 83.9    |	19.9  | 33.3      |[link](https://www.dropbox.com/s/vnjpzq7li2b7tk2/rmc2_d18_l8.pkl?dl=0)|
| rMC3-18  | 8x112x112  | Kinetics | 50.2	  | 62.8    | 83.7	  | 12.5  | 33        |[link](https://www.dropbox.com/s/1vwjomlc45ox6u1/rmc3_d18_l8.pkl?dl=0)|
| rMC4-18  | 8x112x112  | Kinetics | 50.3   |	62.8    | 83.3    |	14.5  | 32        |[link](https://www.dropbox.com/s/zots41ng2xs2ezu/rmc4_d18_l8.pkl?dl=0)|
| rMC5-18  | 8x112x112  | Kinetics | 49.7   |	61.6    | 83.1    |	15.4  | 27.9      |[link](https://www.dropbox.com/s/3e56jjx6x1qot4x/rmc5_d18_l8.pkl?dl=0)|
| **R2.5D-18** | 16x112x112 | Kinetics | 57.3   |	68.5    |	87.5    |	41.5  |	33.3      |[link](https://www.dropbox.com/s/94d2ruqn6tp7xno/r2.5d_d18_l16.pkl?dl=0)|
| R3D-18   | 16x112x112 | Kinetics | 52.9   | 64.7     | 85     | 40.7   | 33.4       |[link](https://www.dropbox.com/s/8tqp8uhjmedflu1/r3d_d18_l16.pkl?dl=0)|
| R2D-18   | 16x112x112 | Kinetics | 47.5    | 59.4     | 81.3     | 2.2   | 11.5       |[link](https://www.dropbox.com/s/hyw8ltzvhadxgia/r2d_d18_l16.pkl?dl=0)|
| fR2D-18  | 16x112x112 | Kinetics | 50.7    | 60.9     | 81.9     | 27.6   | 11.4       |[link](https://www.dropbox.com/s/4yy0tdfebdy0ptr/r2df_d18_l16.pkl?dl=0)|
| MC2-18   | 16x112x112 | Kinetics | 53.6    | 64.8     | 85.1     | 28.5   | 11.4       |[link](https://www.dropbox.com/s/xmtqk2w3p60yly0/mc2_d18_l16.pkl?dl=0)|
| MC3-18   | 16x112x112 | Kinetics | 54.1    | 65.2     | 85.8     | 43.3   | 11.7       |[link](https://www.dropbox.com/s/rpgbzjewagjeu2f/mc3_d18_l16.pkl?dl=0)|
| MC4-18   | 16x112x112 | Kinetics | 54.3 |	65.6 |	85.6 | 40 |	12.7 |[link](https://www.dropbox.com/s/lrjwye0ldsgi2p2/mc4_d18_l16.pkl?dl=0)|
| MC5-18   | 16x112x112 | Kinetics | 54.1 |	65.6 | 85.5 | 39.9 | 16.8 |[link](https://www.dropbox.com/s/3qp62d3159rzwsj/mc5_d18_l16.pkl?dl=0)|
| rMC2-18  | 16x112x112 | Kinetics | 53.5 |	65.4 | 85.5 | 39.8 | 33.3 |[link](https://www.dropbox.com/s/70k3p0xz6rjcdtb/rmc2_d18_l16.pkl?dl=0)|
| rMC3-18  | 16x112x112 | Kinetics | 53.6 |	65.5 | 85.7 | 25 | 33 |[link](https://www.dropbox.com/s/n8eulubwh6l3o0b/rmc3_d18_l16.pkl?dl=0)|
| rMC4-18  | 16x112x112 | Kinetics | 53.9 | 65.6 | 85.3 | 29.1 | 32 |[link](https://www.dropbox.com/s/di3wwadbapc61rn/rmc4_d18_l16.pkl?dl=0)|
| rMC5-18  | 16x112x112 | Kinetics | 52.5 | 63.5 | 84.2 | 30.8 | 27.9 |[link](https://www.dropbox.com/s/lb5jaji177hid7p/rmc5_d18_l16.pkl?dl=0)|
| C3D-16   | 16x112x112 | Kinetics | 52.3   |	63.4    |	84.6    |	38.5  |	64.9      |[link](https://www.dropbox.com/s/hbzn4ykva64avxu/c3d_l16.pkl?dl=0)|

Note that these models are trained from scratch on Kinetics. In this table, all models are ResNet style with 18-layers, except for [C3D](http://www.cs.dartmouth.edu/~dutran/papers/c3d_video.pdf) is VGG style with 16 layers. This table are equivalent to Table 2 in the [paper](https://128.84.21.199/pdf/1711.11248.pdf) where top-1 and top-5 video accuracy are computed by averaging the preditions from **10 clips** per video. To run the evaluation, simply run:

```
sh scripts/test_r2plus1d_kinetics.sh
```

This will give you the result shown in the first row of the table. We also provide deeper models pre-trained on longer clips (e.g. 32 frames).

| Model | Input size | Modality | Pre-trained      | Clip@1 | Video@1 | Video@5 | Download |
| ----- | ---------- | ---------| ------- | ------ | ------- | ------- | -------- |
| R2.5D-34 | 32x112x112 | RGB | Kinetics           | 60.6   | 72.4    | 90.6    | [link](https://www.dropbox.com/s/y6c6jf7myv2w6iq/r2.5d_d34_l32.pkl?dl=0)|
| R2.5D-34 | 32x112x112 | Optical Flow | Sports1M+Kinetics  | 55.9   | 68.2    | 88    | [link](https://www.dropbox.com/s/30zj1t9xte5vy64/r2.5d_d34_l32_ft_sports1m_optical_flow.pkl?dl=0)|
| R2.5D-34 | 32x112x112 | RGB | Sports1M+Kinetics  | 63.9   | 74.2    | 92.1    | [link](https://www.dropbox.com/s/odd9smqn2t54run/r2.5d_d34_l32_ft_sports1m.pkl?dl=0)|

These models are presented in Table 5 of the [paper](https://128.84.21.199/pdf/1711.11248.pdf) with R(2+1)D trained from scratch or pre-trained on [Sports1M](https://cs.stanford.edu/people/karpathy/deepvideo) then fine-tuned on Kinetics. The models are evaluated using **dense prediction** similar to I3D. We densely sample clips from video, and for each clip we extract prediction for its center crop. The clip predictions are averaged to make video prediction. To reproduce these numbers, you need to use `extract_features.py` to compute prediction for clips and then aggregate the predictions.

```
sh scripts/extract_feature_kinetics.sh
sh scripts/extract_feature_kinetics_of.sh
sh scripts/dense_prediction.sh
```
